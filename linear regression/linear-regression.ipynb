{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f98e0e8",
   "metadata": {},
   "source": [
    "#  Linear Regression – In-Depth Explanation with Math Intuition\n",
    "\n",
    "---\n",
    "\n",
    "##  What is Linear Regression?\n",
    "\n",
    "**Linear Regression** is a fundamental supervised learning algorithm used for **predicting a continuous outcome** based on one or more input features.\n",
    "\n",
    "It models the relationship between input variables (**X**) and the target variable (**y**) using a **linear function**.\n",
    "\n",
    "---\n",
    "\n",
    "##  Hypothesis Function\n",
    "\n",
    "For **simple linear regression** (one feature):\n",
    "\n",
    "$\\hat{y} = \\beta_0 + \\beta_1 x$\n",
    "\n",
    "For **multiple features** (multivariate linear regression):\n",
    "\n",
    "\n",
    "$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n$\n",
    "\n",
    "\n",
    "Or in vectorized form:\n",
    "\n",
    "\n",
    "$\\hat{y} = \\mathbf{X}\\boldsymbol{\\beta}$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  Objective: Minimize the Cost Function\n",
    "\n",
    "The most common cost function used is **Mean Squared Error (MSE)**:\n",
    "\n",
    "\n",
    "$J(\\boldsymbol{\\beta}) = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2 = \\frac{1}{n} (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})$\n",
    "\n",
    "We aim to find the optimal **β (coefficients)** that minimize this error.\n",
    "\n",
    "---\n",
    "\n",
    "##  Deriving the Optimal Parameters (Normal Equation)\n",
    "\n",
    "To minimize the cost, take the derivative of the MSE with respect to β and set to zero:\n",
    "\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\boldsymbol{\\beta}} = -2 \\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) = 0$\n",
    "\n",
    "\n",
    "Solving for β:\n",
    "\n",
    "\n",
    "$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T\\mathbf{y}$\n",
    "\n",
    "\n",
    "This is known as the **Normal Equation**.\n",
    "\n",
    "---\n",
    "\n",
    "##  Python Code Example (with scikit-learn)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate example data\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Create and fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Intercept (β0):\", model.intercept_)\n",
    "print(\"Slope (β1):\", model.coef_)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Actual')\n",
    "plt.plot(X, y_pred, color='red', label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"Linear Regression Fit\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
